// src/chatbot.js
import "dotenv/config";
import TelegramBot from "node-telegram-bot-api";
import pg from "pg";
import { OpenAIEmbeddings, ChatOpenAI } from "@langchain/openai";
import { PGVectorStore } from "@langchain/community/vectorstores/pgvector";

// Funci√≥n auxiliar para logs m√°s detallados
function logWithTimestamp(message, data = null) {
  const timestamp = new Date().toISOString().slice(11, 19); // HH:MM:SS
  const prefix = `[${timestamp}]`;

  if (data) {
    console.log(`${prefix} ${message}`, data);
  } else {
    console.log(`${prefix} ${message}`);
  }
}

/* ---------- 1) Conexiones globales ---------- */
logWithTimestamp("üîå Iniciando conexiones a servicios externos...");

const pool = new pg.Pool({
  host: process.env.PGHOST,
  port: process.env.PGPORT,
  user: process.env.PGUSER,
  password: process.env.PGPASSWORD,
  database: process.env.PGDATABASE,
});

logWithTimestamp(
  `üìä Conexi√≥n al pool de PostgreSQL configurada (${process.env.PGHOST}:${process.env.PGPORT})`
);

const embeddings = new OpenAIEmbeddings(); // genera vectores
logWithTimestamp("üß† Modelo de embeddings de OpenAI inicializado");

logWithTimestamp(
  `üóÑÔ∏è Inicializando PGVectorStore con tabla: ${process.env.TABLE_NAME}`
);
const vectorStore = await PGVectorStore.initialize(
  // crea/usa tabla
  embeddings,
  {
    pool,
    tableName: process.env.TABLE_NAME,
    // Especificamos expl√≠citamente los nombres de las columnas para evitar problemas
    columns: {
      idColumnName: "id",
      vectorColumnName: "embedding",
      contentColumnName: "content",
      metadataColumnName: "metadata",
    },
  }
); // docs PGVectorStore :contentReference[oaicite:0]{index=0}
logWithTimestamp("‚úÖ PGVectorStore inicializado correctamente");

const llm = new ChatOpenAI({ temperature: 0, modelName: "gpt-4o" });
logWithTimestamp("ü§ñ Modelo de lenguaje ChatOpenAI (GPT-4o) inicializado");

/* ---------- 2) Arranque del bot de Telegram ---------- */
const bot = new TelegramBot(process.env.TELEGRAM_TOKEN, { polling: true }); // uso b√°sico de node‚Äëtelegram‚Äëbot‚Äëapi :contentReference[oaicite:1]{index=1}
logWithTimestamp("üöÄ Bot de Telegram iniciado y escuchando mensajes");

/* ---------- 3) Handler de mensajes ---------- */
bot.on("message", async (msg) => {
  const chatId = msg.chat.id;
  const userName = msg.from?.first_name || "Usuario";
  const text = msg.text?.trim();

  logWithTimestamp(
    `üì® Mensaje recibido de ${userName} (ID: ${chatId}): "${text}"`
  );

  if (!text || text.startsWith("/")) {
    if (text === "/start") {
      logWithTimestamp(`ü§ù Comando /start recibido de ${userName}`);
      await bot.sendMessage(
        chatId,
        "¬°Hola! Estoy listo para responder tus preguntas sobre el contenido del blog. ¬øQu√© te gustar√≠a saber?"
      );
    } else if (text) {
      logWithTimestamp(`‚ö†Ô∏è Comando no procesado: ${text}`);
    }
    return; // ignora otros comandos
  }

  // Enviar mensaje de espera
  await bot.sendMessage(chatId, "Procesando tu pregunta, dame un momento...");
  logWithTimestamp("üîÑ Enviado mensaje de espera al usuario");

  try {
    /* 3a) Recupera los 4 fragmentos m√°s relevantes */
    logWithTimestamp("üîç Buscando fragmentos relevantes para la consulta...");
    const startSearch = Date.now();
    const docs = await vectorStore.similaritySearch(text, 4);
    const searchTime = ((Date.now() - startSearch) / 1000).toFixed(2);

    logWithTimestamp(
      `üìö Recuperados ${docs.length} fragmentos relevantes en ${searchTime} segundos`
    );

    if (docs.length === 0) {
      logWithTimestamp("‚ö†Ô∏è No se encontraron fragmentos relevantes");
      await bot.sendMessage(
        chatId,
        "No encontr√© informaci√≥n relevante para tu pregunta. ¬øPuedes reformularla?"
      );
      return;
    }

    /* 3b) Construye el contexto para el prompt */
    logWithTimestamp(
      "üìù Construyendo contexto para el prompt con los fragmentos recuperados"
    );
    const context = docs
      .map((d, i) => `(${i + 1}) ${d.pageContent}`)
      .join("\n");

    // Log de los fragmentos recuperados (versi√≥n resumida)
    docs.forEach((doc, i) => {
      const shortContent =
        doc.pageContent.substring(0, 150) +
        (doc.pageContent.length > 150 ? "..." : "");
      logWithTimestamp(`üìÑ Fragmento #${i + 1}:`, shortContent);
    });

    /* 3c) Prompt + llamada al modelo */
    const prompt = `Responde la siguiente pregunta usando S√ìLO la informaci√≥n proporcionada.

${context}

Pregunta: ${text}
Respuesta en espa√±ol:`;

    logWithTimestamp("üß† Enviando consulta al modelo LLM...");
    const startLLM = Date.now();
    const response = await llm.invoke(prompt);
    const llmTime = ((Date.now() - startLLM) / 1000).toFixed(2);

    // Extraer el contenido del mensaje del modelo
    const answer = response.content;
    logWithTimestamp(`‚úÖ Respuesta recibida del modelo en ${llmTime} segundos`);
    logWithTimestamp("üì§ Respuesta del modelo:", answer);

    // Verificar que la respuesta no est√© vac√≠a
    if (!answer || typeof answer !== "string" || answer.trim() === "") {
      throw new Error("La respuesta del modelo est√° vac√≠a");
    }

    /* 3d) Devuelve al usuario */
    await bot.sendMessage(chatId, answer);
    logWithTimestamp(`üì¨ Respuesta enviada a ${userName}`);

    // M√©tricas de tiempo total
    const totalTime = ((Date.now() - startSearch) / 1000).toFixed(2);
    logWithTimestamp(
      `‚è±Ô∏è Tiempo total de procesamiento: ${totalTime} segundos (B√∫squeda: ${searchTime}s, LLM: ${llmTime}s)`
    );
  } catch (err) {
    console.error("‚ùå Error en QA:", err);
    logWithTimestamp("üö® Error al procesar la consulta", err);
    // Asegurar que siempre enviamos un mensaje v√°lido
    await bot.sendMessage(
      chatId,
      "Lo siento, ocurri√≥ un error al procesar tu pregunta. Por favor, int√©ntalo de nuevo m√°s tarde."
    );
    logWithTimestamp("üì§ Mensaje de error enviado al usuario");
  }
});

/* ---------- 4) Cierre limpio si detienes el proceso ---------- */
process.on("SIGINT", async () => {
  logWithTimestamp("‚å®Ô∏è Se√±al de interrupci√≥n recibida. Cerrando conexiones...");
  await pool.end();
  logWithTimestamp("üõë Conexiones cerradas. Terminando el proceso.");
  process.exit(0);
});

// Capturar rechazos de promesas no manejados
process.on("unhandledRejection", (reason, promise) => {
  logWithTimestamp("‚ùå Promesa rechazada no manejada:", reason);
  // No terminamos el proceso para que el bot siga funcionando
});
